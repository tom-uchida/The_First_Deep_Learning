[](2019/05/15)

## 5.1 学習則
- ニューラルネットワークにおいて，学習時にどのように結合強度が変更されるかを記述した法則を学習則という．
- 代表的な学習則に，ヘップ則とデルタ則がある．

### 5.1.1 ヘップ則
- ニューラルネットワークにおける，ヘップ則による伝達効率の増強を数式で表現する．
- 結合強度(重み)の変化量を $\Delta w$，シナプス前のニューロンの興奮の度合い(出力)を $y_i$，シナプス後のニューロンの興奮の度合い(出力)を $y_j$ とすると，以下のような式で表すことができる：

$$
\Delta w = \gamma y_i y_j．
$$

- $\gamma$ は定数で，$y_i$ と $y_j$ がともに大きければ，結合強度は大きく増強される．
- このように，シナプス前後のニューロンの興奮が繰り返し起きることで，次第にシナプスでは情報が効率的に伝達されるようになる．

<br>

### 5.1.2 デルタ則
- デルタ則は，次のルールにより構成されている．
   - 出力と正解の差が大きいほど，重みの修正量を大きくする
   - 入力が大きいほど，重みの修正量を大きくする
- この場合の正解とは，ニューロンの出力の，あるべき値のこと．
- <u>ニューラルネットワークの学習の目的は，出力を正解に近づけること．</u>

<br>

- デルタ則は，次の数式で表される：
$$
\Delta w = \eta (y_j - t) y_i．
$$

- $\Delta w$ は重みの変化量，$y_i$ はシナプス前のニューロンの出力，$y_j$ はシナプス後のニューロンの出力．
- $t$ は正解の値，$\eta$ は学習係数．
- デルタ則により，理想の状態と離れているほど，理想の状態に戻るための重みの修正量が大きくなる．
- また，ニューロンへ大きな入力があれば，シナプスに強い刺激があったとみなされ，重みは変化しやすくなる．